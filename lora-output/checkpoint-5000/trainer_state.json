{
  "best_metric": 2.654310941696167,
  "best_model_checkpoint": "/DATA/Shubham/Projects/Kashmiri_language_Translation/lora-output/checkpoint-3500",
  "epoch": 23.121387283236995,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.4624277456647399,
      "grad_norm": 0.16604332625865936,
      "learning_rate": 2.5e-06,
      "loss": 2.9935,
      "num_input_tokens_seen": 51840,
      "step": 100
    },
    {
      "epoch": 0.9248554913294798,
      "grad_norm": 0.19616317749023438,
      "learning_rate": 5e-06,
      "loss": 3.0358,
      "num_input_tokens_seen": 103520,
      "step": 200
    },
    {
      "epoch": 1.3872832369942196,
      "grad_norm": 0.14323770999908447,
      "learning_rate": 7.5e-06,
      "loss": 3.0508,
      "num_input_tokens_seen": 155616,
      "step": 300
    },
    {
      "epoch": 1.8497109826589595,
      "grad_norm": 0.1625935286283493,
      "learning_rate": 1e-05,
      "loss": 2.9332,
      "num_input_tokens_seen": 207392,
      "step": 400
    },
    {
      "epoch": 2.3121387283236996,
      "grad_norm": 0.19253432750701904,
      "learning_rate": 1.25e-05,
      "loss": 2.969,
      "num_input_tokens_seen": 259200,
      "step": 500
    },
    {
      "epoch": 2.3121387283236996,
      "eval_BLEU": 9.925194705010995,
      "eval_chrF": 35.8267341535891,
      "eval_loss": 2.9496328830718994,
      "eval_runtime": 182.1606,
      "eval_samples_per_second": 5.424,
      "eval_steps_per_second": 1.356,
      "num_input_tokens_seen": 259200,
      "step": 500
    },
    {
      "epoch": 2.7745664739884393,
      "grad_norm": 0.19441558420658112,
      "learning_rate": 1.5e-05,
      "loss": 2.8973,
      "num_input_tokens_seen": 310976,
      "step": 600
    },
    {
      "epoch": 3.2369942196531793,
      "grad_norm": 0.20745468139648438,
      "learning_rate": 1.75e-05,
      "loss": 2.8564,
      "num_input_tokens_seen": 362560,
      "step": 700
    },
    {
      "epoch": 3.699421965317919,
      "grad_norm": 0.24710442125797272,
      "learning_rate": 2e-05,
      "loss": 2.8579,
      "num_input_tokens_seen": 414208,
      "step": 800
    },
    {
      "epoch": 4.161849710982659,
      "grad_norm": 0.3300570547580719,
      "learning_rate": 2.25e-05,
      "loss": 2.8405,
      "num_input_tokens_seen": 466112,
      "step": 900
    },
    {
      "epoch": 4.624277456647399,
      "grad_norm": 0.3187517523765564,
      "learning_rate": 2.5e-05,
      "loss": 2.8121,
      "num_input_tokens_seen": 517920,
      "step": 1000
    },
    {
      "epoch": 4.624277456647399,
      "eval_BLEU": 10.725098840683302,
      "eval_chrF": 36.94819816010974,
      "eval_loss": 2.8369457721710205,
      "eval_runtime": 173.4472,
      "eval_samples_per_second": 5.696,
      "eval_steps_per_second": 1.424,
      "num_input_tokens_seen": 517920,
      "step": 1000
    },
    {
      "epoch": 5.086705202312139,
      "grad_norm": 0.33328405022621155,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 2.7832,
      "num_input_tokens_seen": 569728,
      "step": 1100
    },
    {
      "epoch": 5.5491329479768785,
      "grad_norm": 0.41264963150024414,
      "learning_rate": 3e-05,
      "loss": 2.7935,
      "num_input_tokens_seen": 621344,
      "step": 1200
    },
    {
      "epoch": 6.011560693641618,
      "grad_norm": 0.3927074670791626,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.7202,
      "num_input_tokens_seen": 673184,
      "step": 1300
    },
    {
      "epoch": 6.473988439306359,
      "grad_norm": 0.4404023587703705,
      "learning_rate": 3.5e-05,
      "loss": 2.728,
      "num_input_tokens_seen": 725056,
      "step": 1400
    },
    {
      "epoch": 6.936416184971098,
      "grad_norm": 0.4512110650539398,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.7216,
      "num_input_tokens_seen": 776160,
      "step": 1500
    },
    {
      "epoch": 6.936416184971098,
      "eval_BLEU": 12.337734062899791,
      "eval_chrF": 38.68671168931611,
      "eval_loss": 2.7620420455932617,
      "eval_runtime": 146.3352,
      "eval_samples_per_second": 6.752,
      "eval_steps_per_second": 1.688,
      "num_input_tokens_seen": 776160,
      "step": 1500
    },
    {
      "epoch": 7.398843930635838,
      "grad_norm": 0.542327344417572,
      "learning_rate": 4e-05,
      "loss": 2.6848,
      "num_input_tokens_seen": 828000,
      "step": 1600
    },
    {
      "epoch": 7.861271676300578,
      "grad_norm": 0.650080144405365,
      "learning_rate": 4.25e-05,
      "loss": 2.6755,
      "num_input_tokens_seen": 879936,
      "step": 1700
    },
    {
      "epoch": 8.323699421965317,
      "grad_norm": 0.6853964328765869,
      "learning_rate": 4.5e-05,
      "loss": 2.6515,
      "num_input_tokens_seen": 931744,
      "step": 1800
    },
    {
      "epoch": 8.786127167630058,
      "grad_norm": 0.8034394383430481,
      "learning_rate": 4.75e-05,
      "loss": 2.6472,
      "num_input_tokens_seen": 983488,
      "step": 1900
    },
    {
      "epoch": 9.248554913294798,
      "grad_norm": 0.7567545771598816,
      "learning_rate": 5e-05,
      "loss": 2.5787,
      "num_input_tokens_seen": 1035360,
      "step": 2000
    },
    {
      "epoch": 9.248554913294798,
      "eval_BLEU": 12.59132828476018,
      "eval_chrF": 39.173138997186975,
      "eval_loss": 2.7090699672698975,
      "eval_runtime": 165.8393,
      "eval_samples_per_second": 5.958,
      "eval_steps_per_second": 1.489,
      "num_input_tokens_seen": 1035360,
      "step": 2000
    },
    {
      "epoch": 9.710982658959537,
      "grad_norm": 0.8895062208175659,
      "learning_rate": 5.25e-05,
      "loss": 2.5817,
      "num_input_tokens_seen": 1087040,
      "step": 2100
    },
    {
      "epoch": 10.173410404624278,
      "grad_norm": 0.9627028703689575,
      "learning_rate": 5.500000000000001e-05,
      "loss": 2.5659,
      "num_input_tokens_seen": 1138752,
      "step": 2200
    },
    {
      "epoch": 10.635838150289018,
      "grad_norm": 1.0560802221298218,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 2.5549,
      "num_input_tokens_seen": 1190400,
      "step": 2300
    },
    {
      "epoch": 11.098265895953757,
      "grad_norm": 1.049614429473877,
      "learning_rate": 6e-05,
      "loss": 2.5349,
      "num_input_tokens_seen": 1242176,
      "step": 2400
    },
    {
      "epoch": 11.560693641618498,
      "grad_norm": 1.1987591981887817,
      "learning_rate": 6.25e-05,
      "loss": 2.5149,
      "num_input_tokens_seen": 1293920,
      "step": 2500
    },
    {
      "epoch": 11.560693641618498,
      "eval_BLEU": 13.053994962438907,
      "eval_chrF": 39.51038161564541,
      "eval_loss": 2.6678905487060547,
      "eval_runtime": 161.822,
      "eval_samples_per_second": 6.105,
      "eval_steps_per_second": 1.526,
      "num_input_tokens_seen": 1293920,
      "step": 2500
    },
    {
      "epoch": 12.023121387283236,
      "grad_norm": 1.1394094228744507,
      "learning_rate": 6.500000000000001e-05,
      "loss": 2.4873,
      "num_input_tokens_seen": 1345600,
      "step": 2600
    },
    {
      "epoch": 12.485549132947977,
      "grad_norm": 1.1227549314498901,
      "learning_rate": 6.750000000000001e-05,
      "loss": 2.447,
      "num_input_tokens_seen": 1397472,
      "step": 2700
    },
    {
      "epoch": 12.947976878612717,
      "grad_norm": 1.469218373298645,
      "learning_rate": 7e-05,
      "loss": 2.465,
      "num_input_tokens_seen": 1448608,
      "step": 2800
    },
    {
      "epoch": 13.410404624277456,
      "grad_norm": 1.602501392364502,
      "learning_rate": 7.25e-05,
      "loss": 2.4377,
      "num_input_tokens_seen": 1500544,
      "step": 2900
    },
    {
      "epoch": 13.872832369942197,
      "grad_norm": 1.868011474609375,
      "learning_rate": 7.500000000000001e-05,
      "loss": 2.4072,
      "num_input_tokens_seen": 1552192,
      "step": 3000
    },
    {
      "epoch": 13.872832369942197,
      "eval_BLEU": 13.269227330492722,
      "eval_chrF": 39.82499860993913,
      "eval_loss": 2.6557228565216064,
      "eval_runtime": 164.4598,
      "eval_samples_per_second": 6.008,
      "eval_steps_per_second": 1.502,
      "num_input_tokens_seen": 1552192,
      "step": 3000
    },
    {
      "epoch": 14.335260115606937,
      "grad_norm": 1.783909559249878,
      "learning_rate": 7.75e-05,
      "loss": 2.361,
      "num_input_tokens_seen": 1604096,
      "step": 3100
    },
    {
      "epoch": 14.797687861271676,
      "grad_norm": 1.8978036642074585,
      "learning_rate": 8e-05,
      "loss": 2.3769,
      "num_input_tokens_seen": 1655808,
      "step": 3200
    },
    {
      "epoch": 15.260115606936417,
      "grad_norm": 1.8873234987258911,
      "learning_rate": 8.25e-05,
      "loss": 2.3402,
      "num_input_tokens_seen": 1707648,
      "step": 3300
    },
    {
      "epoch": 15.722543352601155,
      "grad_norm": 1.6982097625732422,
      "learning_rate": 8.5e-05,
      "loss": 2.3322,
      "num_input_tokens_seen": 1759360,
      "step": 3400
    },
    {
      "epoch": 16.184971098265898,
      "grad_norm": 1.8422586917877197,
      "learning_rate": 8.75e-05,
      "loss": 2.3272,
      "num_input_tokens_seen": 1810912,
      "step": 3500
    },
    {
      "epoch": 16.184971098265898,
      "eval_BLEU": 13.381847738132171,
      "eval_chrF": 39.948963832274096,
      "eval_loss": 2.654310941696167,
      "eval_runtime": 170.8973,
      "eval_samples_per_second": 5.781,
      "eval_steps_per_second": 1.445,
      "num_input_tokens_seen": 1810912,
      "step": 3500
    },
    {
      "epoch": 16.647398843930635,
      "grad_norm": 2.0838420391082764,
      "learning_rate": 9e-05,
      "loss": 2.2794,
      "num_input_tokens_seen": 1862464,
      "step": 3600
    },
    {
      "epoch": 17.109826589595375,
      "grad_norm": 2.1898927688598633,
      "learning_rate": 9.250000000000001e-05,
      "loss": 2.3135,
      "num_input_tokens_seen": 1914496,
      "step": 3700
    },
    {
      "epoch": 17.572254335260116,
      "grad_norm": 2.1980233192443848,
      "learning_rate": 9.5e-05,
      "loss": 2.2506,
      "num_input_tokens_seen": 1966368,
      "step": 3800
    },
    {
      "epoch": 18.034682080924856,
      "grad_norm": 1.8694267272949219,
      "learning_rate": 9.75e-05,
      "loss": 2.2475,
      "num_input_tokens_seen": 2018112,
      "step": 3900
    },
    {
      "epoch": 18.497109826589597,
      "grad_norm": 2.1032357215881348,
      "learning_rate": 0.0001,
      "loss": 2.2121,
      "num_input_tokens_seen": 2069792,
      "step": 4000
    },
    {
      "epoch": 18.497109826589597,
      "eval_BLEU": 12.903548381984836,
      "eval_chrF": 39.40442940569211,
      "eval_loss": 2.660281181335449,
      "eval_runtime": 167.0627,
      "eval_samples_per_second": 5.914,
      "eval_steps_per_second": 1.478,
      "num_input_tokens_seen": 2069792,
      "step": 4000
    },
    {
      "epoch": 18.959537572254334,
      "grad_norm": 2.018472194671631,
      "learning_rate": 9.877295966495897e-05,
      "loss": 2.2218,
      "num_input_tokens_seen": 2121056,
      "step": 4100
    },
    {
      "epoch": 19.421965317919074,
      "grad_norm": 2.387342691421509,
      "learning_rate": 9.759000729485331e-05,
      "loss": 2.192,
      "num_input_tokens_seen": 2173056,
      "step": 4200
    },
    {
      "epoch": 19.884393063583815,
      "grad_norm": 2.492733955383301,
      "learning_rate": 9.644856443408244e-05,
      "loss": 2.1659,
      "num_input_tokens_seen": 2224768,
      "step": 4300
    },
    {
      "epoch": 20.346820809248555,
      "grad_norm": 2.822174310684204,
      "learning_rate": 9.534625892455923e-05,
      "loss": 2.1554,
      "num_input_tokens_seen": 2276640,
      "step": 4400
    },
    {
      "epoch": 20.809248554913296,
      "grad_norm": 2.5869998931884766,
      "learning_rate": 9.428090415820635e-05,
      "loss": 2.1374,
      "num_input_tokens_seen": 2328384,
      "step": 4500
    },
    {
      "epoch": 20.809248554913296,
      "eval_BLEU": 14.195550704241567,
      "eval_chrF": 39.942617588760065,
      "eval_loss": 2.6605734825134277,
      "eval_runtime": 175.4834,
      "eval_samples_per_second": 5.63,
      "eval_steps_per_second": 1.408,
      "num_input_tokens_seen": 2328384,
      "step": 4500
    },
    {
      "epoch": 21.271676300578033,
      "grad_norm": 2.200315475463867,
      "learning_rate": 9.325048082403138e-05,
      "loss": 2.0893,
      "num_input_tokens_seen": 2380128,
      "step": 4600
    },
    {
      "epoch": 21.734104046242773,
      "grad_norm": 2.6838042736053467,
      "learning_rate": 9.226293653104342e-05,
      "loss": 2.1286,
      "num_input_tokens_seen": 2431840,
      "step": 4700
    },
    {
      "epoch": 22.196531791907514,
      "grad_norm": 3.7903635501861572,
      "learning_rate": 9.130611700711997e-05,
      "loss": 2.0959,
      "num_input_tokens_seen": 2483424,
      "step": 4800
    },
    {
      "epoch": 22.658959537572255,
      "grad_norm": 3.598986864089966,
      "learning_rate": 9.03692348738122e-05,
      "loss": 2.0538,
      "num_input_tokens_seen": 2535264,
      "step": 4900
    },
    {
      "epoch": 23.121387283236995,
      "grad_norm": 2.4402623176574707,
      "learning_rate": 8.946061301216421e-05,
      "loss": 2.0757,
      "num_input_tokens_seen": 2586944,
      "step": 5000
    },
    {
      "epoch": 23.121387283236995,
      "eval_BLEU": 13.374734115702273,
      "eval_chrF": 39.96136599485528,
      "eval_loss": 2.691972017288208,
      "eval_runtime": 168.5681,
      "eval_samples_per_second": 5.861,
      "eval_steps_per_second": 1.465,
      "num_input_tokens_seen": 2586944,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 2586944,
  "num_train_epochs": 24,
  "save_steps": 500,
  "total_flos": 1.490651934621696e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
